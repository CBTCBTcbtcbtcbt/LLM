<!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>LLM API &#x4ea4;&#x4e92;&#x9879;&#x76ee; &mdash; &#x5f00;&#x53d1;&#x8005;&#x6280;&#x672f;&#x6587;&#x6863;</title>
            <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only],
.vscode-high-contrast:not(.vscode-high-contrast-light) img[src$=\#gh-light-mode-only],
.vscode-high-contrast-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
            
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
<style>
:root {
  --color-note: #0969da;
  --color-tip: #1a7f37;
  --color-warning: #9a6700;
  --color-severe: #bc4c00;
  --color-caution: #d1242f;
  --color-important: #8250df;
}

</style>
<style>
@media (prefers-color-scheme: dark) {
  :root {
    --color-note: #2f81f7;
    --color-tip: #3fb950;
    --color-warning: #d29922;
    --color-severe: #db6d28;
    --color-caution: #f85149;
    --color-important: #a371f7;
  }
}

</style>
<style>
.markdown-alert {
  padding: 0.5rem 1rem;
  margin-bottom: 16px;
  color: inherit;
  border-left: .25em solid #888;
}

.markdown-alert>:first-child {
  margin-top: 0
}

.markdown-alert>:last-child {
  margin-bottom: 0
}

.markdown-alert .markdown-alert-title {
  display: flex;
  font-weight: 500;
  align-items: center;
  line-height: 1
}

.markdown-alert .markdown-alert-title .octicon {
  margin-right: 0.5rem;
  display: inline-block;
  overflow: visible !important;
  vertical-align: text-bottom;
  fill: currentColor;
}

.markdown-alert.markdown-alert-note {
  border-left-color: var(--color-note);
}

.markdown-alert.markdown-alert-note .markdown-alert-title {
  color: var(--color-note);
}

.markdown-alert.markdown-alert-important {
  border-left-color: var(--color-important);
}

.markdown-alert.markdown-alert-important .markdown-alert-title {
  color: var(--color-important);
}

.markdown-alert.markdown-alert-warning {
  border-left-color: var(--color-warning);
}

.markdown-alert.markdown-alert-warning .markdown-alert-title {
  color: var(--color-warning);
}

.markdown-alert.markdown-alert-tip {
  border-left-color: var(--color-tip);
}

.markdown-alert.markdown-alert-tip .markdown-alert-title {
  color: var(--color-tip);
}

.markdown-alert.markdown-alert-caution {
  border-left-color: var(--color-caution);
}

.markdown-alert.markdown-alert-caution .markdown-alert-title {
  color: var(--color-caution);
}

</style>
        
        </head>
        <body class="vscode-body vscode-light">
            <h1 id="llm-api-交互项目--开发者技术文档">LLM API 交互项目 — 开发者技术文档</h1>
<p>面向：希望在该项目基础上进行二次开发、扩展新能力（新增提供商、定制智能体、构建多智能体系统）的工程师。</p>
<p>目标：系统阐述架构设计、核心模块、数据流、配置管理、扩展指南、运行示例、测试与调试、性能与安全等，帮助开发者快速理解并高质量地构建功能。</p>
<hr>
<h2 id="1-背景与设计目标">1. 背景与设计目标</h2>
<p>本项目是一个模块化的 Python 工程，用于通过 API 与大语言模型（LLM）进行交互。项目遵循面向对象设计原则（OOP），在保证清晰性的同时，强调：</p>
<ul>
<li>低耦合：客户端、对话、智能体、编排彼此独立。</li>
<li>可扩展：采用抽象基类与工厂函数，便于新增 LLM 提供商与场景。</li>
<li>易用性：提供简单的 CLI 聊天入口与多种示例。</li>
<li>可维护：类型标注、清晰的模块职责、简单直观的数据流。</li>
</ul>
<hr>
<h2 id="2-术语约定">2. 术语约定</h2>
<ul>
<li>Provider（提供商）：LLM 服务商，例如 OpenAI、Anthropic。</li>
<li>Client（客户端）：具体 Provider 的 API 调用封装，例如 <code>OpenAIClient</code>。</li>
<li>Conversation（对话）：维护消息历史与上下文的会话容器。</li>
<li>Agent（智能体）：封装角色与个性的行为体，基于 <code>Conversation</code> 与 <code>LLMClient</code>。</li>
<li>MultiAgent（多智能体）：协调多个 Agent 的交互编排组件。</li>
<li>Streaming（流式）：服务端按增量片段返回内容的模式，适合实时输出。</li>
</ul>
<hr>
<h2 id="3-项目结构">3. 项目结构</h2>
<pre><code>LLM/
├── config.yaml              # API 配置文件
├── llm_client.py           # 核心 LLM 客户端模块（抽象/具体实现）
├── conversation.py         # 对话管理模块（历史、系统提示、流式发送）
├── agent.py                # 智能体基类 + WerewolfPlayer 示例
├── multi_agent.py          # 多智能体系统 + WerewolfGame 示例
├── chat.py                 # CLI 聊天入口（基于配置）
├── requirements.txt        # 依赖包
├── examples/               # 示例代码
│   ├── simple_chat.py     # 简单对话示例
│   ├── agent_example.py   # 智能体示例
│   └── werewolf_game.py   # 狼人杀游戏示例
└── README.md              # 项目简要说明
</code></pre>
<p>运行环境与依赖：</p>
<ul>
<li>Python 3.9+（建议）</li>
<li>依赖：<code>requests&gt;=2.31.0</code>, <code>pyyaml&gt;=6.0.1</code></li>
</ul>
<hr>
<h2 id="4-架构总览">4. 架构总览</h2>
<p>核心构件与关系：</p>
<ul>
<li><code>LLMClient</code>（抽象）定义通用接口：<code>chat()</code> 与 <code>stream_chat()</code>。</li>
<li>具体客户端：<code>OpenAIClient</code>、<code>AnthropicClient</code> 实现 HTTP 调用与流式解析。</li>
<li><code>Conversation</code> 管理消息历史与系统提示，提供 <code>send()</code> 与 <code>stream_send()</code>。</li>
<li><code>Agent</code> 封装角色与个性，内部持有 <code>Conversation</code>，提供 <code>respond()</code> / <code>stream_respond()</code>。</li>
<li><code>MultiAgentSystem</code> 协调多个 <code>Agent</code> 的交互（广播、轮询），<code>WerewolfGame</code> 为特化示例。</li>
<li><code>chat.py</code> 基于 <code>config.yaml</code> 组装客户端与会话，实现 CLI 交互与流式输出。</li>
</ul>
<p>数据流（简化）：</p>
<ol>
<li>加载配置 → <code>create_client()</code> 创建指定 Provider 的客户端。</li>
<li>创建 <code>Conversation</code> → 收发用户消息。</li>
<li><code>Conversation.send()</code> 或 <code>stream_send()</code> 调用 <code>client.chat()</code> / <code>client.stream_chat()</code>。</li>
<li>响应被追加到会话历史并返回/实时输出。</li>
</ol>
<hr>
<h2 id="5-模块详解与接口参考">5. 模块详解与接口参考</h2>
<h3 id="51-llm_clientpy">5.1 llm_client.py</h3>
<p>核心类与函数：</p>
<pre><code class="language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">LLMClient</span>(<span class="hljs-title class_ inherited__">ABC</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, api_key: <span class="hljs-built_in">str</span>, model: <span class="hljs-built_in">str</span>, **kwargs</span>): ...
<span class="hljs-meta">    @abstractmethod</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">chat</span>(<span class="hljs-params">self, messages: <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]], **kwargs</span>) -&gt; <span class="hljs-built_in">str</span>: ...
<span class="hljs-meta">    @abstractmethod</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">stream_chat</span>(<span class="hljs-params">self, messages: <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]], **kwargs</span>): ...

<span class="hljs-keyword">class</span> <span class="hljs-title class_">OpenAIClient</span>(<span class="hljs-title class_ inherited__">LLMClient</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, api_key: <span class="hljs-built_in">str</span>, model: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,
                 base_url: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;https://api.openai.com/v1&quot;</span>, **kwargs</span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">chat</span>(<span class="hljs-params">self, messages: <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]], **kwargs</span>) -&gt; <span class="hljs-built_in">str</span>: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">stream_chat</span>(<span class="hljs-params">self, messages: <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]], **kwargs</span>): ...

<span class="hljs-keyword">class</span> <span class="hljs-title class_">AnthropicClient</span>(<span class="hljs-title class_ inherited__">LLMClient</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, api_key: <span class="hljs-built_in">str</span>, model: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;claude-3-sonnet-20240229&quot;</span>,
                 base_url: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;https://api.anthropic.com&quot;</span>, **kwargs</span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">chat</span>(<span class="hljs-params">self, messages: <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]], **kwargs</span>) -&gt; <span class="hljs-built_in">str</span>: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">stream_chat</span>(<span class="hljs-params">self, messages: <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]], **kwargs</span>): ...

<span class="hljs-keyword">def</span> <span class="hljs-title function_">create_client</span>(<span class="hljs-params">provider: <span class="hljs-built_in">str</span>, **config</span>) -&gt; LLMClient: ...
</code></pre>
<ul>
<li>
<p>公共配置：</p>
<ul>
<li><code>api_key</code>: 服务商密钥</li>
<li><code>model</code>: 模型名称</li>
<li><code>temperature</code>: 默认 0.7（可在 <code>kwargs</code> 传入覆盖）</li>
<li><code>max_tokens</code>: 默认 2000（可在 <code>kwargs</code> 传入覆盖）</li>
<li><code>base_url</code>: 服务端基础 URL（对 OpenAI/Anthropic 都支持传入）</li>
</ul>
</li>
<li>
<p>OpenAI 请求：</p>
<ul>
<li>URL: <code>POST {base_url}/chat/completions</code></li>
<li>Headers: <code>Authorization: Bearer &lt;api_key&gt;</code>, <code>Content-Type: application/json</code></li>
<li>Body: <code>{ model, messages, temperature, max_tokens }</code></li>
<li>响应解析：<code>response.json()['choices'][0]['message']['content']</code></li>
</ul>
</li>
<li>
<p>OpenAI 流式：</p>
<ul>
<li>在请求体加 <code>stream: True</code></li>
<li>通过 <code>response.iter_lines()</code> 读取 SSE 风格的 <code>data: ...</code> 行，遇到 <code>data: [DONE]</code> 结束。</li>
<li>增量片段在 <code>choices[0].delta.content</code>。</li>
</ul>
</li>
<li>
<p>Anthropic 请求：</p>
<ul>
<li>URL: <code>POST {base_url}/v1/messages</code></li>
<li>Headers: <code>x-api-key</code>, <code>anthropic-version: 2023-06-01</code>, <code>Content-Type: application/json</code></li>
<li>Body: <code>{ model, messages, temperature, max_tokens }</code></li>
<li>响应解析：<code>response.json()['content'][0]['text']</code></li>
</ul>
</li>
<li>
<p>Anthropic 流式：</p>
<ul>
<li>在请求体加 <code>stream: True</code></li>
<li>通过 SSE <code>data: ...</code> 行解析，<code>type == 'content_block_delta'</code> 时增量文本位于 <code>delta.text</code>。</li>
</ul>
</li>
<li>
<p>错误处理：</p>
<ul>
<li>均调用 <code>response.raise_for_status()</code>，网络或服务端错误将抛出 <code>requests.HTTPError</code>。</li>
<li>建议扩展：设置 <code>timeout</code>、重试、退避、错误分类与日志。</li>
</ul>
</li>
<li>
<p>扩展新的 Provider：</p>
<ol>
<li>继承 <code>LLMClient</code>，实现 <code>chat()</code> 与 <code>stream_chat()</code>。</li>
<li>在 <code>create_client()</code> 的 <code>clients</code> 映射中注册新类。</li>
<li>实现 Provider 特有的认证、URL、请求与流式解析。</li>
</ol>
</li>
</ul>
<p>消息格式（与 OpenAI 对齐）：</p>
<pre><code class="language-json"><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;role&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;system|user|assistant&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;文本内容&quot;</span>
<span class="hljs-punctuation">}</span>
</code></pre>
<h3 id="52-conversationpy">5.2 <a href="http://conversation.py">conversation.py</a></h3>
<p>职责：维护会话历史与系统提示，提供阻塞与流式发送。</p>
<p>关键接口：</p>
<pre><code class="language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Conversation</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, client: LLMClient, system_prompt: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span></span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add_message</span>(<span class="hljs-params">self, role: <span class="hljs-built_in">str</span>, content: <span class="hljs-built_in">str</span></span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">send</span>(<span class="hljs-params">self, user_message: <span class="hljs-built_in">str</span>, **kwargs</span>) -&gt; <span class="hljs-built_in">str</span>: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">stream_send</span>(<span class="hljs-params">self, user_message: <span class="hljs-built_in">str</span>, **kwargs</span>): ...  <span class="hljs-comment"># 生成器，yield 增量</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">clear</span>(<span class="hljs-params">self</span>): ...  <span class="hljs-comment"># 保留系统提示（如存在），清空其它消息</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_history</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]]: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_system_prompt</span>(<span class="hljs-params">self, prompt: <span class="hljs-built_in">str</span></span>): ...
</code></pre>
<p>流式逻辑：</p>
<ul>
<li>先追加用户消息 → 调用 <code>client.stream_chat(messages, **kwargs)</code> → 持续累计 <code>full_response</code> 并 <code>yield</code> chunk → 结束后将完整回复追加到历史。</li>
</ul>
<h3 id="53-agentpy">5.3 <a href="http://agent.py">agent.py</a></h3>
<p>职责：基于角色与个性构建 <code>system_prompt</code>，对外暴露面向场景的响应接口。</p>
<p>关键接口：</p>
<pre><code class="language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Agent</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name: <span class="hljs-built_in">str</span>, client: LLMClient, role: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;&quot;</span>, personality: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;&quot;</span></span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">respond</span>(<span class="hljs-params">self, message: <span class="hljs-built_in">str</span>, **kwargs</span>) -&gt; <span class="hljs-built_in">str</span>: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">stream_respond</span>(<span class="hljs-params">self, message: <span class="hljs-built_in">str</span>, **kwargs</span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset</span>(<span class="hljs-params">self</span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_history</span>(<span class="hljs-params">self</span>): ...
</code></pre>
<p>系统提示构建：</p>
<ul>
<li>由 <code>role</code> 与 <code>personality</code> 拼装，示例格式：</li>
</ul>
<pre><code>Role: 你是一位耐心的老师
Personality: 友好且鼓励学生
</code></pre>
<p>特化示例：</p>
<ul>
<li><code>WerewolfPlayer(Agent)</code>：根据角色类型（werewolf、villager、seer、doctor、hunter）设定不同个性与提示。</li>
</ul>
<h3 id="54-multi_agentpy">5.4 multi_agent.py</h3>
<p>职责：对多个 <code>Agent</code> 进行编排，支持广播与轮询对话。</p>
<p>关键接口：</p>
<pre><code class="language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiAgentSystem</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add_agent</span>(<span class="hljs-params">self, agent: Agent</span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_agent</span>(<span class="hljs-params">self, name: <span class="hljs-built_in">str</span></span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_agent</span>(<span class="hljs-params">self, name: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">Optional</span>[Agent]: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">broadcast</span>(<span class="hljs-params">self, message: <span class="hljs-built_in">str</span>, exclude: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>] = <span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">round_robin</span>(<span class="hljs-params">self, initial_message: <span class="hljs-built_in">str</span>, rounds: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]]: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset_all</span>(<span class="hljs-params">self</span>): ...

<span class="hljs-keyword">class</span> <span class="hljs-title class_">WerewolfGame</span>(<span class="hljs-title class_ inherited__">MultiAgentSystem</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">start_game</span>(<span class="hljs-params">self</span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">night_phase</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">day_phase</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>]: ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">eliminate_player</span>(<span class="hljs-params">self, player_name: <span class="hljs-built_in">str</span></span>): ...
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">next_day</span>(<span class="hljs-params">self</span>): ...
</code></pre>
<p>说明：</p>
<ul>
<li><code>round_robin</code> 会将当前轮次最后一个回复拼接为下一轮的 <code>current_message</code>，形成串联对话。</li>
<li><code>WerewolfGame</code> 维护 <code>game_state</code>（phase/day/alive/dead），以简单规则驱动阶段提示。</li>
</ul>
<h3 id="55-chatpycli-入口">5.5 <a href="http://chat.py">chat.py</a>（CLI 入口）</h3>
<p>职责：读取配置，创建客户端与会话，提供交互式命令行聊天。</p>
<p>关键逻辑：</p>
<pre><code class="language-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_config</span>(<span class="hljs-params">config_path: <span class="hljs-built_in">str</span> = <span class="hljs-string">&quot;config.yaml&quot;</span></span>) -&gt; <span class="hljs-built_in">dict</span>: ...

<span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
    config = load_config()
    api_config = config[<span class="hljs-string">&#x27;api&#x27;</span>]
    client = create_client(...)
    conversation = Conversation(client)
    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
        user_input = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;You: &quot;</span>).strip()
        <span class="hljs-keyword">if</span> user_input == <span class="hljs-string">&#x27;quit&#x27;</span>: <span class="hljs-keyword">break</span>
        <span class="hljs-keyword">if</span> user_input == <span class="hljs-string">&#x27;clear&#x27;</span>: conversation.clear(); <span class="hljs-keyword">continue</span>
        <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> conversation.stream_send(user_input):
            <span class="hljs-built_in">print</span>(chunk, end=<span class="hljs-string">&quot;&quot;</span>, flush=<span class="hljs-literal">True</span>)
</code></pre>
<p>交互指令：</p>
<ul>
<li><code>quit</code>: 退出</li>
<li><code>clear</code>: 清空对话（保留系统提示）</li>
</ul>
<hr>
<h2 id="6-配置管理">6. 配置管理</h2>
<p>示例（见 <a href="http://README.html">README.md</a>）：</p>
<pre><code class="language-yaml"><span class="hljs-attr">api:</span>
  <span class="hljs-attr">provider:</span> <span class="hljs-string">&quot;openai&quot;</span>
  <span class="hljs-attr">api_key:</span> <span class="hljs-string">&quot;your-api-key-here&quot;</span>
  <span class="hljs-attr">model:</span> <span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>
  <span class="hljs-attr">base_url:</span> <span class="hljs-string">&quot;https://api.openai.com/v1&quot;</span>
  <span class="hljs-attr">temperature:</span> <span class="hljs-number">0.7</span>
  <span class="hljs-attr">max_tokens:</span> <span class="hljs-number">2000</span>
</code></pre>
<p>说明：</p>
<ul>
<li><code>provider</code>: 必填，当前支持 <code>openai</code>、<code>anthropic</code>。</li>
<li><code>api_key</code>: 必填，建议通过环境变量或密钥管理工具注入。</li>
<li><code>model</code>: 必填，参照各 Provider 的模型列表。</li>
<li><code>base_url</code>: 选填，默认指向官方地址，企业/代理场景可自定义。</li>
<li><code>temperature</code>、<code>max_tokens</code>: 可在配置或调用时覆盖。</li>
</ul>
<p>安全建议：</p>
<ul>
<li>不要将明文 <code>api_key</code> 提交到版本库。</li>
<li>针对多环境，将 <code>config.yaml</code> 抽象为模板，并使用外部注入敏感变量。</li>
</ul>
<hr>
<h2 id="7-扩展指南">7. 扩展指南</h2>
<h3 id="71-新增-llm-提供商">7.1 新增 LLM 提供商</h3>
<p>步骤：</p>
<ol>
<li>新建类 <code>MyProviderClient(LLMClient)</code>，实现 <code>chat()</code> 与 <code>stream_chat()</code>。</li>
<li>处理认证（Headers）、URL、请求体与响应解析（含流式）。</li>
<li>在 <code>create_client()</code> 的 <code>clients</code> 中注册：<code>'myprovider': MyProviderClient</code>。</li>
</ol>
<p>注意点：</p>
<ul>
<li>流式返回通常是 SSE（Server-Sent Events）或自定义分段协议，需正确解析与错误处理。</li>
<li>统一消息格式（role/content）以复用 <code>Conversation</code> 与 <code>Agent</code>。</li>
</ul>
<h3 id="72-自定义-agent-行为">7.2 自定义 Agent 行为</h3>
<p>思路：</p>
<ul>
<li>继承 <code>Agent</code> 并重写 <code>__init__()</code> 或新增方法，构建更复杂的系统提示（如工具使用、风格约束）。</li>
<li>复用 <code>Conversation</code>：可在 <code>respond()</code> 前注入 <code>system</code> 或 <code>assistant</code> 提示，引导模型输出。</li>
</ul>
<p>示例：</p>
<pre><code class="language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CodeReviewer</span>(<span class="hljs-title class_ inherited__">Agent</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, client</span>):
        <span class="hljs-built_in">super</span>().__init__(name, client,
            role=<span class="hljs-string">&quot;你是一名严格的代码评审专家&quot;</span>,
            personality=<span class="hljs-string">&quot;简洁、可执行建议优先&quot;</span>)
</code></pre>
<h3 id="73-扩展多智能体编排">7.3 扩展多智能体编排</h3>
<ul>
<li>替换 <code>round_robin</code> 为更复杂的调度（如基于话题路由、上下文聚合、裁判评分）。</li>
<li>在 <code>broadcast</code> 前后插入中间件（如内容过滤、记忆写入、工具调用）。</li>
<li>引入共享工作记忆（vector store/数据库）以实现更强协作。</li>
</ul>
<hr>
<h2 id="8-错误处理与健壮性建议">8. 错误处理与健壮性建议</h2>
<p>当前实现：</p>
<ul>
<li>HTTP 层使用 <code>response.raise_for_status()</code> 直接抛错。</li>
<li>流式解析遇到 <code>json.JSONDecodeError</code> 时跳过该行继续，对不规范服务返回具有容错性。</li>
</ul>
<p>建议补强：</p>
<ul>
<li>设置请求 <code>timeout</code>，并引入重试（指数退避）。</li>
<li>捕获并分类错误：网络错误、认证错误、参数错误、配额限制（429）等。</li>
<li>结构化日志（请求耗时、模型、token、错误码），便于运维与成本控制。</li>
<li>输入校验（messages 结构、role 合法性、max_tokens 范围）。</li>
</ul>
<hr>
<h2 id="9-性能成本与并发">9. 性能、成本与并发</h2>
<ul>
<li>流式优点：降低首字延迟，提升交互体验；建议在 CLI 与 UI 中默认启用。</li>
<li><code>max_tokens</code> 与 <code>temperature</code> 对性能与成本影响明显，应按场景调优。</li>
<li>并发：当前未内置并发调度；服务端限流时需在上层加入队列与重试。</li>
<li>缓存：可在上层对常见系统提示与少量问答做缓存，降低成本。</li>
</ul>
<hr>
<h2 id="10-安全与合规">10. 安全与合规</h2>
<ul>
<li>API Key 管理：使用环境变量/密钥管理服务；避免日志泄露。</li>
<li>数据敏感性：避免将敏感输入/输出写入明文日志或持久化储存。</li>
<li>访问控制：若部署在服务器侧，确保网络与凭证权限边界清晰。</li>
<li>成本控制：限制最大轮次与 token；对异常循环输出做截断保护。</li>
</ul>
<hr>
<h2 id="11-测试与调试建议">11. 测试与调试建议</h2>
<ul>
<li>单元测试：
<ul>
<li>使用 <code>requests</code> 的 mocking/fake server 验证 <code>chat()</code> 与 <code>stream_chat()</code> 行为。</li>
<li>对 <code>Conversation</code> 的历史操作（<code>add_message</code>、<code>clear</code>、<code>set_system_prompt</code>）做断言。</li>
<li>对 <code>MultiAgentSystem.broadcast/round_robin</code> 的交互结果进行一致性测试。</li>
</ul>
</li>
<li>集成测试：
<ul>
<li>在沙箱/API 速率限制宽松环境下运行 <code>examples/</code>，确保端到端串通。</li>
</ul>
</li>
<li>调试：
<ul>
<li>增加可选的 <code>debug</code> 标志输出请求体与响应段（注意隐私）。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="12-示例讲解">12. 示例讲解</h2>
<h3 id="121-examplessimple_chatpy">12.1 <code>examples/simple_chat.py</code></h3>
<ul>
<li>创建 <code>client</code> → 构造 <code>Conversation(system_prompt=...)</code> → 连续 <code>send()</code> 两次输出结果。</li>
<li>用法简洁，适合作为最小可用 Demo。</li>
</ul>
<h3 id="122-examplesagent_examplepy">12.2 <code>examples/agent_example.py</code></h3>
<ul>
<li>创建两个角色不同的 <code>Agent</code>（Teacher/Scientist），对同一问题生成不同风格的回答。</li>
<li>演示了角色与个性对系统提示的影响。</li>
</ul>
<h3 id="123-exampleswerewolf_gamepy">12.3 <code>examples/werewolf_game.py</code></h3>
<ul>
<li>构造 <code>WerewolfGame</code>，加入多名玩家（不同角色），启动游戏并分别在夜间与白天阶段进行广播式交互。</li>
<li>展示了多智能体编排与特化场景设计。</li>
</ul>
<hr>
<h2 id="13-常见问题faq与坑位">13. 常见问题（FAQ）与坑位</h2>
<ul>
<li>为什么响应为空或报错？
<ul>
<li>检查 <code>api_key</code> 是否有效、<code>model</code> 与 <code>base_url</code> 是否正确、网络是否可达。</li>
</ul>
</li>
<li>流式输出乱码或停滞？
<ul>
<li>核查服务端的 SSE 格式与解析逻辑，确认 <code>data: [DONE]</code> 终止条件。</li>
</ul>
</li>
<li>会话越聊越长导致成本上升？
<ul>
<li>定期 <code>clear()</code>，或实现截断策略（仅保留最近 N 轮）。</li>
</ul>
</li>
<li>不同 Provider 的消息格式不完全一致？
<ul>
<li>项目统一使用 <code>role/content</code> 结构，必要时在客户端中做转换适配。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="14-未来改进方向">14. 未来改进方向</h2>
<ul>
<li>引入统一的错误模型与重试策略（含退避与幂等设计）。</li>
<li>增加日志与可观测性（请求耗时、token 计量、成本报表）。</li>
<li>支持函数调用（Tool-Use）与外部工具集成（检索/执行器）。</li>
<li>多智能体的更高级编排（话题路由、记忆共享、角色分工与评审）。</li>
<li>提供 Web UI 与更丰富的示例（插件化场景）。</li>
</ul>
<hr>
<h2 id="15-版本与兼容性">15. 版本与兼容性</h2>
<ul>
<li>依赖：<code>requests&gt;=2.31.0</code>, <code>pyyaml&gt;=6.0.1</code></li>
<li>Python：建议 3.9+；注意 <code>typing</code> 兼容性（<code>List/Dict/Optional</code>）。</li>
<li>Provider：当前支持 OpenAI 与 Anthropic，其他需自行扩展并适配。</li>
</ul>
<hr>
<h2 id="16-附录接口速查与代码片段">16. 附录：接口速查与代码片段</h2>
<ul>
<li>创建客户端（工厂）：</li>
</ul>
<pre><code class="language-python">client = create_client(
    provider=<span class="hljs-string">&quot;openai&quot;</span>,
    api_key=<span class="hljs-string">&quot;&lt;KEY&gt;&quot;</span>,
    model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,
    base_url=<span class="hljs-string">&quot;https://api.openai.com/v1&quot;</span>,
    temperature=<span class="hljs-number">0.7</span>,
    max_tokens=<span class="hljs-number">2000</span>,
)
</code></pre>
<ul>
<li>会话阻塞式：</li>
</ul>
<pre><code class="language-python">conv = Conversation(client, system_prompt=<span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>)
<span class="hljs-built_in">print</span>(conv.send(<span class="hljs-string">&quot;Hello!&quot;</span>))
</code></pre>
<ul>
<li>会话流式：</li>
</ul>
<pre><code class="language-python"><span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> conv.stream_send(<span class="hljs-string">&quot;Tell me a joke&quot;</span>):
    <span class="hljs-built_in">print</span>(chunk, end=<span class="hljs-string">&quot;&quot;</span>, flush=<span class="hljs-literal">True</span>)
</code></pre>
<ul>
<li>Agent：</li>
</ul>
<pre><code class="language-python">teacher = Agent(
    name=<span class="hljs-string">&quot;Teacher&quot;</span>,
    client=client,
    role=<span class="hljs-string">&quot;你是一位耐心的老师&quot;</span>,
    personality=<span class="hljs-string">&quot;友好且鼓励学生&quot;</span>,
)
<span class="hljs-built_in">print</span>(teacher.respond(<span class="hljs-string">&quot;什么是光合作用？&quot;</span>))
</code></pre>
<ul>
<li>多智能体：</li>
</ul>
<pre><code class="language-python">system = MultiAgentSystem()
system.add_agent(teacher)
system.add_agent(Agent(<span class="hljs-string">&quot;Scientist&quot;</span>, client, role=<span class="hljs-string">&quot;科学家&quot;</span>, personality=<span class="hljs-string">&quot;严谨&quot;</span>))
<span class="hljs-built_in">print</span>(system.broadcast(<span class="hljs-string">&quot;讨论一下气候变化&quot;</span>))
<span class="hljs-built_in">print</span>(system.round_robin(<span class="hljs-string">&quot;开始讨论&quot;</span>, rounds=<span class="hljs-number">2</span>))
</code></pre>
<hr>
<h2 id="17-运行与验证">17. 运行与验证</h2>
<ul>
<li>安装依赖：<code>pip install -r requirements.txt</code></li>
<li>配置密钥：编辑 <code>config.yaml</code></li>
<li>启动 CLI：<code>python chat.py</code></li>
<li>运行示例：<code>python examples/simple_chat.py</code> 等</li>
</ul>
<hr>
<h2 id="18-许可与声明">18. 许可与声明</h2>
<ul>
<li>本项目仅供学习与研究使用。</li>
<li>使用第三方 LLM 时需遵循对应服务条款与合规要求。</li>
</ul>

            
            
        </body>
        </html>